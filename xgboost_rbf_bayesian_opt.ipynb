{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xgboost-rbf-bayesian-opt.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyrcha/ml-rants/blob/master/xgboost_rbf_bayesian_opt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Myqz8SMey7wF",
        "colab_type": "text"
      },
      "source": [
        "# Optimizing XGBoost and Random Forests with Bayesian Optimiztion\n",
        "\n",
        "Inspired by [this post](https://www.kdnuggets.com/2019/07/xgboost-random-forest-bayesian-optimisation.html) we will create a full end-to-end pipeline with these three ML algorithms on a regression dataset. More specifically we will use the [Energy efficiency dataset](https://archive.ics.uci.edu/ml/datasets/energy+efficiency) from the UCI repository.\n",
        "\n",
        "We begin by importing the dataset (after some preprocessing from the original dataset which is in xls format)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0WMLZoN9Xro",
        "colab_type": "code",
        "outputId": "0697f9c9-5b86-4349-c58c-d488800fd981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"ENB2012_data.csv\", sep=\";\")\n",
        "data.describe()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>Y1</th>\n",
              "      <th>Y2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.00000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.00000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.764167</td>\n",
              "      <td>671.708333</td>\n",
              "      <td>318.500000</td>\n",
              "      <td>176.604167</td>\n",
              "      <td>5.25000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>0.234375</td>\n",
              "      <td>2.81250</td>\n",
              "      <td>22.307201</td>\n",
              "      <td>24.587760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.105777</td>\n",
              "      <td>88.086116</td>\n",
              "      <td>43.626481</td>\n",
              "      <td>45.165950</td>\n",
              "      <td>1.75114</td>\n",
              "      <td>1.118763</td>\n",
              "      <td>0.133221</td>\n",
              "      <td>1.55096</td>\n",
              "      <td>10.090196</td>\n",
              "      <td>9.513306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.620000</td>\n",
              "      <td>514.500000</td>\n",
              "      <td>245.000000</td>\n",
              "      <td>110.250000</td>\n",
              "      <td>3.50000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>6.010000</td>\n",
              "      <td>10.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.682500</td>\n",
              "      <td>606.375000</td>\n",
              "      <td>294.000000</td>\n",
              "      <td>140.875000</td>\n",
              "      <td>3.50000</td>\n",
              "      <td>2.750000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.75000</td>\n",
              "      <td>12.992500</td>\n",
              "      <td>15.620000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.750000</td>\n",
              "      <td>673.750000</td>\n",
              "      <td>318.500000</td>\n",
              "      <td>183.750000</td>\n",
              "      <td>5.25000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>3.00000</td>\n",
              "      <td>18.950000</td>\n",
              "      <td>22.080000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.830000</td>\n",
              "      <td>741.125000</td>\n",
              "      <td>343.000000</td>\n",
              "      <td>220.500000</td>\n",
              "      <td>7.00000</td>\n",
              "      <td>4.250000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>4.00000</td>\n",
              "      <td>31.667500</td>\n",
              "      <td>33.132500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.980000</td>\n",
              "      <td>808.500000</td>\n",
              "      <td>416.500000</td>\n",
              "      <td>220.500000</td>\n",
              "      <td>7.00000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>5.00000</td>\n",
              "      <td>43.100000</td>\n",
              "      <td>48.030000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               X1          X2          X3  ...         X8          Y1          Y2\n",
              "count  768.000000  768.000000  768.000000  ...  768.00000  768.000000  768.000000\n",
              "mean     0.764167  671.708333  318.500000  ...    2.81250   22.307201   24.587760\n",
              "std      0.105777   88.086116   43.626481  ...    1.55096   10.090196    9.513306\n",
              "min      0.620000  514.500000  245.000000  ...    0.00000    6.010000   10.900000\n",
              "25%      0.682500  606.375000  294.000000  ...    1.75000   12.992500   15.620000\n",
              "50%      0.750000  673.750000  318.500000  ...    3.00000   18.950000   22.080000\n",
              "75%      0.830000  741.125000  343.000000  ...    4.00000   31.667500   33.132500\n",
              "max      0.980000  808.500000  416.500000  ...    5.00000   43.100000   48.030000\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e-tH5UG907g",
        "colab_type": "text"
      },
      "source": [
        "We will split the dataset using a 80-20% split, randomly, keeping 80% for training (with cross validation for tuning hyperparams with Bayesian optimization) and 20% for testing (checking the generalization error)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhqcEG5q9-NE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data.drop(labels=['Y1', 'Y2'], axis=1)\n",
        "y = data['Y2']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YN5W63L-_ZKu",
        "colab_type": "text"
      },
      "source": [
        "Let's train using CV, a Random Forest regressor with default values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5K_7fJy-pzp",
        "colab_type": "code",
        "outputId": "a8694fa5-a4dd-4e9b-edb6-f156fdf001dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "CV_plain_rf_score = abs(cross_val_score(\n",
        "     RandomForestRegressor(random_state=42),  \n",
        "     X=X_train, \n",
        "     y=y_train, \n",
        "     cv=10,\n",
        "     scoring=\"neg_mean_squared_error\",\n",
        "     n_jobs=-1).mean())\n",
        "\n",
        "model_plain_rf = RandomForestRegressor(n_jobs=-1, random_state=42)\n",
        "model_plain_rf.fit(X_train, y_train)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
              "                      max_features='auto', max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
              "                      oob_score=False, random_state=42, verbose=0,\n",
              "                      warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QPheqhaAEph",
        "colab_type": "code",
        "outputId": "b715085b-ff7a-4f5d-8745-cd2cc6579c32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "pred_train = model_plain_rf.predict(X_train)\n",
        "pred_test = model_plain_rf.predict(X_test)\n",
        "\n",
        "print(\"Training MSE: {0:.2f}\".format(mean_squared_error(y_train, pred_train)))\n",
        "print(\"CV MSE: {0:.2f}\".format(abs(CV_plain_rf_score)))\n",
        "print(\"Testing MSE: {0:.2f}\".format(mean_squared_error(y_test, pred_test)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training MSE: 0.48\n",
            "CV MSE: 3.14\n",
            "Testing MSE: 3.65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBEC5KgkBT6p",
        "colab_type": "text"
      },
      "source": [
        "Let's also check the XGBoost model with default parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxK3ef3vBElb",
        "colab_type": "code",
        "outputId": "95d6be58-293a-4dc4-9971-e3c733cf1c14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "CV_xgb_plain_score_ = abs(cross_val_score(\n",
        "     xgb.XGBRegressor(random_state=42),  \n",
        "     X=X_train, \n",
        "     y=y_train, \n",
        "     cv=10,\n",
        "     scoring=\"neg_mean_squared_error\",\n",
        "     n_jobs=-1).mean())\n",
        "\n",
        "\n",
        "model_plain_xgb = xgb.XGBRegressor(random_state=42)\n",
        "model_plain_xgb.fit(X_train, y_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14:07:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
              "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
              "             n_jobs=1, nthread=None, objective='reg:linear', random_state=42,\n",
              "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "             silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2Ww3weCDGIU",
        "colab_type": "code",
        "outputId": "3b48e7dd-4bb9-455a-8ba5-5b3277f9d495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "pred_train = model_plain_xgb.predict(X_train)\n",
        "pred_test = model_plain_xgb.predict(X_test)\n",
        "\n",
        "print(\"Training MSE: {0:.2f}\".format(mean_squared_error(y_train, pred_train)))\n",
        "print(\"CV MSE: {0:.2f}\".format(abs(CV_xgb_plain_score_)))\n",
        "print(\"Testing MSE: {0:.2f}\".format(mean_squared_error(y_test, pred_test)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training MSE: 1.82\n",
            "CV MSE: 2.36\n",
            "Testing MSE: 2.50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fPkhYyRQJ_z",
        "colab_type": "text"
      },
      "source": [
        "## Bayesian Optimization\n",
        "\n",
        "We will begin by installing the [Bayesian optimization package](https://github.com/fmfn/BayesianOptimization) and then creating functions to optimize the hyperparameters of the two algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYn-vctoQadT",
        "colab_type": "code",
        "outputId": "c7b737c2-6b69-4b90-e859-2a4db2395017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "!pip install bayesian-optimization"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/72/0c/173ac467d0a53e33e41b521e4ceba74a8ac7c7873d7b857a8fbdca88302d/bayesian-optimization-1.0.1.tar.gz\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.21.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.13.2)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/0d/3b/6b9d4477a34b3905f246ff4e7acf6aafd4cc9b77d473629b77\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdD4NHwIQMy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "def bayesian_optimization(dataset, function, parameters):\n",
        "   X_train, y_train = dataset\n",
        "   n_iterations = 10\n",
        "   gp_params = {\"alpha\": 1e-4}\n",
        "\n",
        "   BO = BayesianOptimization(function, parameters)\n",
        "   BO.maximize(n_iter=n_iterations, **gp_params)\n",
        "\n",
        "   return BO.max"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ejkdeI2CZ24",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "be987e1b-00d1-4fa8-a718-439d55aa47f9"
      },
      "source": [
        "def rfc_optimization(cv_splits):\n",
        "    def function(n_estimators, max_depth, min_samples_split):\n",
        "        return cross_val_score(\n",
        "               RandomForestRegressor(\n",
        "                   n_estimators=int(max(n_estimators,0)),                                                               \n",
        "                   max_depth=int(max(max_depth,1)),\n",
        "                   min_samples_split=int(max(min_samples_split,2)), \n",
        "                   n_jobs=-1, \n",
        "                   random_state=42),  \n",
        "               X=X_train, \n",
        "               y=y_train, \n",
        "               cv=cv_splits,\n",
        "               scoring=\"neg_mean_squared_error\",\n",
        "               n_jobs=-1).mean()\n",
        "\n",
        "    parameters = {\"n_estimators\": (10, 1000),\n",
        "                  \"max_depth\": (1, 150),\n",
        "                  \"min_samples_split\": (2, 10)}\n",
        "    \n",
        "    return function, parameters\n",
        "  \n",
        "f, p = rfc_optimization(10)\n",
        "dataset = (X_train, y_train)\n",
        "best_solution = bayesian_optimization(dataset, f, p) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | max_depth | min_sa... | n_esti... |\n",
            "-------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-2.931   \u001b[0m | \u001b[0m 31.4    \u001b[0m | \u001b[0m 3.828   \u001b[0m | \u001b[0m 216.6   \u001b[0m |\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m-3.131   \u001b[0m | \u001b[0m 125.3   \u001b[0m | \u001b[0m 5.407   \u001b[0m | \u001b[0m 108.7   \u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m-3.116   \u001b[0m | \u001b[0m 80.17   \u001b[0m | \u001b[0m 5.37    \u001b[0m | \u001b[0m 102.3   \u001b[0m |\n",
            "| \u001b[95m 4       \u001b[0m | \u001b[95m-2.881   \u001b[0m | \u001b[95m 147.5   \u001b[0m | \u001b[95m 2.498   \u001b[0m | \u001b[95m 762.5   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m-3.199   \u001b[0m | \u001b[0m 108.9   \u001b[0m | \u001b[0m 9.787   \u001b[0m | \u001b[0m 47.21   \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m-17.93   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1e+03   \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m-3.209   \u001b[0m | \u001b[0m 94.54   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 196.3   \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m-2.888   \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 693.6   \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m-3.187   \u001b[0m | \u001b[0m 80.65   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 710.2   \u001b[0m |\n",
            "| \u001b[95m 10      \u001b[0m | \u001b[95m-2.854   \u001b[0m | \u001b[95m 40.78   \u001b[0m | \u001b[95m 2.0     \u001b[0m | \u001b[95m 316.0   \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m-2.865   \u001b[0m | \u001b[0m 144.9   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 349.5   \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m-2.953   \u001b[0m | \u001b[0m 82.02   \u001b[0m | \u001b[0m 3.694   \u001b[0m | \u001b[0m 454.2   \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m-3.187   \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 545.3   \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m-17.93   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 561.1   \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m-2.939   \u001b[0m | \u001b[0m 98.16   \u001b[0m | \u001b[0m 3.332   \u001b[0m | \u001b[0m 394.8   \u001b[0m |\n",
            "=============================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkYdNTkA1aVh",
        "colab_type": "text"
      },
      "source": [
        "Based on this optimization procedure we have:\n",
        "\n",
        "*  n_estimators = 316\n",
        "*  min_samples_split = 2\n",
        "*  max_depth = 40\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN1-zqbRQNOL",
        "colab_type": "code",
        "outputId": "6086bf53-703d-42ab-d92f-7044a79a7baf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "params = best_solution[\"params\"]\n",
        "\n",
        "model = RandomForestRegressor(\n",
        "             n_estimators=int(max(params[\"n_estimators\"], 0)),\n",
        "             max_depth=int(max(params[\"max_depth\"], 1)),\n",
        "             min_samples_split=int(max(params[\"min_samples_split\"], 2)), \n",
        "             n_jobs=-1, \n",
        "             random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=40,\n",
              "                      max_features='auto', max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, n_estimators=316, n_jobs=-1,\n",
              "                      oob_score=False, random_state=42, verbose=0,\n",
              "                      warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bmwiogbpe25",
        "colab_type": "code",
        "outputId": "cfdad715-b535-40ec-ec61-5f4d1924e737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "pred_train = model.predict(X_train)\n",
        "pred_test = model.predict(X_test)\n",
        "\n",
        "print(\"Training MSE: {0:.2f}\".format(mean_squared_error(y_train, pred_train)))\n",
        "print(\"CV MSE: {0:.2f}\".format(2.854))\n",
        "print(\"Testing MSE: {0:.2f}\".format(mean_squared_error(y_test, pred_test)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training MSE: 0.37\n",
            "CV MSE: 2.85\n",
            "Testing MSE: 3.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERlKPfA6pjSh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "5092df22-bd3b-463c-c701-9c1dddc4ca19"
      },
      "source": [
        "def xgb_optimization(cv_splits):\n",
        "    def function(eta, gamma, max_depth):\n",
        "            return cross_val_score(\n",
        "                   xgb.XGBRegressor(\n",
        "                       objective=\"reg:squarederror\",\n",
        "                       learning_rate=max(eta, 0),\n",
        "                       gamma=max(gamma, 0),\n",
        "                       max_depth=int(max_depth),                                               \n",
        "                       seed=42,\n",
        "                       nthread=-1),  \n",
        "                   X=X_train, \n",
        "                   y=y_train, \n",
        "                   cv=cv_splits,\n",
        "                   scoring=\"neg_mean_squared_error\",\n",
        "                   n_jobs=-1).mean()\n",
        "\n",
        "    parameters = {\"eta\": (0.001, 0.4),\n",
        "                  \"gamma\": (0, 20),\n",
        "                  \"max_depth\": (1, 2000)}\n",
        "    \n",
        "    return function, parameters\n",
        "  \n",
        "\n",
        "f, p = xgb_optimization(10)\n",
        "dataset = (X_train, y_train)\n",
        "best_solution = bayesian_optimization(dataset, f, p) \n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   |    eta    |   gamma   | max_depth |\n",
            "-------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-1.467   \u001b[0m | \u001b[0m 0.2486  \u001b[0m | \u001b[0m 3.14    \u001b[0m | \u001b[0m 1.485e+0\u001b[0m |\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m-1.499   \u001b[0m | \u001b[0m 0.2835  \u001b[0m | \u001b[0m 8.228   \u001b[0m | \u001b[0m 471.5   \u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m-1.895   \u001b[0m | \u001b[0m 0.3508  \u001b[0m | \u001b[0m 11.09   \u001b[0m | \u001b[0m 5.861   \u001b[0m |\n",
            "| \u001b[95m 4       \u001b[0m | \u001b[95m-1.356   \u001b[0m | \u001b[95m 0.1632  \u001b[0m | \u001b[95m 1.355   \u001b[0m | \u001b[95m 91.55   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m-2.137   \u001b[0m | \u001b[0m 0.06769 \u001b[0m | \u001b[0m 16.84   \u001b[0m | \u001b[0m 1.966e+0\u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m-544.1   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.041e+0\u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m-1.651   \u001b[0m | \u001b[0m 0.2585  \u001b[0m | \u001b[0m 6.305   \u001b[0m | \u001b[0m 49.36   \u001b[0m |\n",
            "| \u001b[95m 8       \u001b[0m | \u001b[95m-1.319   \u001b[0m | \u001b[95m 0.1819  \u001b[0m | \u001b[95m 2.295   \u001b[0m | \u001b[95m 78.51   \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m-1.646   \u001b[0m | \u001b[0m 0.3446  \u001b[0m | \u001b[0m 10.87   \u001b[0m | \u001b[0m 23.62   \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m-544.1   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.579   \u001b[0m | \u001b[0m 84.03   \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m-2.03    \u001b[0m | \u001b[0m 0.1575  \u001b[0m | \u001b[0m 17.66   \u001b[0m | \u001b[0m 357.7   \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m-1.908   \u001b[0m | \u001b[0m 0.1076  \u001b[0m | \u001b[0m 12.11   \u001b[0m | \u001b[0m 725.3   \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m-2.034   \u001b[0m | \u001b[0m 0.1213  \u001b[0m | \u001b[0m 16.94   \u001b[0m | \u001b[0m 558.9   \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m-1.571   \u001b[0m | \u001b[0m 0.1449  \u001b[0m | \u001b[0m 6.503   \u001b[0m | \u001b[0m 1.634e+0\u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m-1.882   \u001b[0m | \u001b[0m 0.1211  \u001b[0m | \u001b[0m 15.13   \u001b[0m | \u001b[0m 1.067e+0\u001b[0m |\n",
            "=============================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjPIXA6x3DO3",
        "colab_type": "text"
      },
      "source": [
        "For XGBoost we have the optimal parameters found:\n",
        "\n",
        "*  max_depth = 78\n",
        "*  gamma = 2.295\n",
        "*  eta = 0.1819"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8PgDduU6k-3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "7e869fee-6181-4a62-a0bc-9de052bf1cef"
      },
      "source": [
        "params = best_solution[\"params\"]\n",
        "\n",
        "model = xgb.XGBRegressor(objective=\"reg:squarederror\",\n",
        "                 learning_rate=max(params[\"eta\"], 0),\n",
        "                 gamma=max(params[\"gamma\"], 1),\n",
        "                 max_depth=int(max(params[\"max_depth\"], 2)),                                               \n",
        "                 seed=42,\n",
        "                 nthread=-1)\n",
        "\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=1, gamma=2.295287077901593,\n",
              "             importance_type='gain', learning_rate=0.18193061733363647,\n",
              "             max_delta_step=0, max_depth=78, min_child_weight=1, missing=None,\n",
              "             n_estimators=100, n_jobs=1, nthread=-1,\n",
              "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
              "             reg_lambda=1, scale_pos_weight=1, seed=42, silent=None,\n",
              "             subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB6hrPu69rIb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a8da5d09-20e3-46dc-e934-8538dfa14baa"
      },
      "source": [
        "pred_train = model.predict(X_train)\n",
        "pred_test = model.predict(X_test)\n",
        "\n",
        "print(\"Training MSE: {0:.2f}\".format(mean_squared_error(y_train, pred_train)))\n",
        "print(\"CV MSE: {0:.2f}\".format(1.319))\n",
        "print(\"Testing MSE: {0:.2f}\".format(mean_squared_error(y_test, pred_test)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training MSE: 0.25\n",
            "CV MSE: 1.32\n",
            "Testing MSE: 1.34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMGLn7jo9z47",
        "colab_type": "text"
      },
      "source": [
        "## Final Results\n",
        "\n",
        "To conclude we constructed the following matrix for the CV and test errors:\n",
        "\n",
        "|  Model | CV MSE | Test MSE  | \n",
        "|---|---|---|\n",
        "| RF default params |   3.14 | 3.65  | \n",
        "| XGBoost default params  |  2.36 | 2.50  | \n",
        "| RF optimized params  | 2.85  | 3.05  | \n",
        "| XGBoost optimized params  | 1.32  | 1.34  | \n",
        "\n",
        "Bayesian optimization indeed provided boost in performance in a more \"clever\" manner than grid or random search.\n"
      ]
    }
  ]
}